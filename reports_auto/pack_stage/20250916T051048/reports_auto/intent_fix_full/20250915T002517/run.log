[*] LOGDIR = reports_auto/intent_fix_full/20250915T002517
[PKL] intent/intent/artifacts/intent_pro_cal.pkl
[rules_feat] vendor: vendor/rules_features.py
[PIPELINE_STEPS] [('features', 'FeatureUnion'), ('clf', 'CalibratedClassifierCV')]
[EXPECTED] 29233
[BRANCH_DIMS] {"word": 3834, "char": 25392, "rules": "ERR:NameError"}
[SUM_BEFORE] 29226
[SAVED] artifacts/intent_pipeline_aligned.pkl
[PRED_FAIL] NameError name '_sp' is not defined

[*] å ±å‘Šè³‡æ–™å¤¾ï¼šreports_auto/intent_fix_full/20250915T002517
åˆ‡åˆ°é€™é¡†ï¼š export SMA_INTENT_ML_PKL="$PWD/artifacts/intent_pipeline_aligned.pkl"
[?2004h(.venv) ]0;youjie@DESKTOP-MP3QVS6: ~/projects/smart-mail-agent-ssot-pro[01;32myoujie@DESKTOP-MP3QVS6[00m:[01;34m~/projects/smart-mail-agent-ssot-pro[00m$ # scripts/intent_import_and_align.sh
# ç”¨é€”ï¼šå¾ intent/** æ‰¾å›èˆŠæ¨¡å‹ â†’ ç¶è¨“ç·´æ™‚ rules_featï¼ˆshim æœƒè‡ªè¼‰ï¼‰â†’ å°é½Š ZeroPad â†’ å…¨ç¨‹è½åœ°
set -Eeuo pipefail -o errtrace

ROOT="${ROOT:-$HOME/projects/smart-mail-agent-ssot-pro}"
cd "$ROOT"; [ -f .venv/bin/activate ] && . .venv/bin/activate || true
export PYTHONNOUSERSITE=1
export PYTHONPATH="src:vendor:${PYTHONPATH:-}"

TS="$(date +%Y%m%dT%H%M%S)"
R="reports_auto/intent_fix_full/${TS}"
mkdir -p "$R" artifacts vendor/sma_tools vendor
exec > >(tee "$R/run.log") 2>&1

open_dir() {
  if command -v explorer.exe >/dev/null 2>&1; then
    explorer.exe "$(wslpath -w "$R")" >/dev/null 2>&1 || true
  elif command -v xdg-open >/dev/null 2>&1; then
    xdg-open "$R" >/dev/null 2>&1 || true
  fi
  echo "[*] å ±å‘Šè³‡æ–™å¤¾ï¼š$R"
}

trap 'code=$?; {
  echo "=== BASH_TRAP ==="
  echo "TIME: $(date -Is)"
  echo "BASH_COMMAND: ${BASH_COMMAND:-<none>}"
  echo "EXIT_CODE: ${code}"
} >> "$R/last_trace.txt"; open_dir; exit $code' ERR INT TERM

echo "[*] LOGDIR = $R"# 0) æœ€å° sma_tools.ZeroPadï¼ˆèˆŠç®¡ç·šæœƒ import åˆ°ï¼‰mkdir -p vendor/sma_toolscat > vendor/sma_tools/__init__.py <<'PY'__all__ = ["sk_zero_pad"]PYcat > vendor/sma_tools/sk_zero_pad.py <<'PY'from __future__ import annotationsimport numpy as npfrom scipy import sparse as spfrom sklearn.base import BaseEstimator, TransformerMixinclass ZeroPad(BaseEstimator, TransformerMixin):    def __init__(self, width: int = 1, dtype=np.float64, **kwargs):        try: self.width = int(width) if width else 1        except Exception: self.width = 1        self.dtype = dtype        self._extra = dict(kwargs)    def __setstate__(self, state):        self.__dict__.update(state or {})        if not hasattr(self, "width"): self.width = 1        if not hasattr(self, "dtype"): self.dtype = np.float64    def fit(self, X, y=None): return self    def transform(self, X): return sp.csr_matrix((len(X), self.width), dtype=self.dtype)PY# 1) rules_feat shimï¼šå…ˆå˜—è©¦è¼‰å…¥å£“ç¸®åŒ…å…§çš„ runtime_threshold_router.pyï¼›å¤±æ•—æ‰é€€å› 1 ç¶­ zerocat > vendor/rules_features.py <<'PY'# auto-generated shim: map vendor.rules_features.rules_feat -> bundle's runtime_threshold_router.rules_featimport sys, glob, importlib.util as _iluimport numpy as _npfrom scipy import sparse as _spdef _load_rules_from_bundle():    # æ‰¾ intent/**/.sma_tools/runtime_threshold_router.pyï¼ˆå–æ™‚é–“æœ€æ–°ï¼‰    paths = sorted(glob.glob("intent/**/.sma_tools/runtime_threshold_router.py", recursive=True),                   key=lambda p: (__import__("os").path.getmtime(p)), reverse=True)    for p in paths:        spec = _ilu.spec_from_file_location("intent_bundle.rules_runtime", p)        if spec and spec.loader:            mod = _ilu.module_from_spec(spec)            try:                spec.loader.exec_module(mod)                if hasattr(mod, "rules_feat"):                    return mod.rules_feat            except Exception:                continue    return None_rules = _load_rules_from_bundle()if _rules is not None:    rules_feat = _ruleselse:    # å®‰å…¨å¾Œå‚™ï¼š1 ç¶­ zeroï¼ˆå¾ŒçºŒç”±å°é½Šå™¨è£œ pad å¯¬åº¦ï¼‰    def rules_feat(texts):        return _sp.csr_matrix(_np.zeros((len(texts), 1), dtype=_np.float64))PY# 2) å°é½Šå™¨ï¼šè¼‰å…¥èˆŠ PKL â†’ æª¢å‡ºåˆ†æ”¯ç¶­åº¦ â†’ èˆ‡ clf.n_features_in_ å°é½Š â†’ è½åœ° + ç…™å›ªæ¸¬python - <<'PY' "$R"import os, sys, json, glob, traceback, faulthandlerfrom pathlib import Pathimport joblib, numpy as npfrom scipy import sparse as spR = Path(sys.argv[1]); R.mkdir(parents=True, exist_ok=True)py_log = (R/"py_run.log").open("w", encoding="utf-8")faulthandler.enable(py_log)def pick_pkl():    cands = []    for pat in ["intent/**/artifacts/intent_pro_cal.pkl",                "intent/**/artifacts/intent_pipeline*.pkl",                "intent/artifacts/*.pkl"]:        cands += [Path(p) for p in glob.glob(pat, recursive=True)]    cands = [p for p in cands if p.is_file()]    cands.sort(key=lambda p: p.stat().st_mtime, reverse=True)    return cands[0] if cands else Nonedef unwrap(obj):    if hasattr(obj, "predict"): return obj    if isinstance(obj, dict):        for k in ("pipe","pipeline","estimator","clf","model"):            v = obj.get(k);             if hasattr(v, "predict"): return v    return objdef to_csr(X):    if sp.issparse(X): return X.tocsr()    if isinstance(X, np.ndarray): return sp.csr_matrix(X if X.ndim==2 else X.reshape(1,-1))    raise TypeError(f"non-numeric branch output: {type(X)}")def feature_dims(feat, xs):    dims = {}    if hasattr(feat, "transformer_list"):        for name, sub in feat.transformer_list:            try:                Y = to_csr(sub.transform(xs))                dims[name] = int(Y.shape[1])            except Exception as e:                dims[name] = f"ERR:{type(e).__name__}"    return dimstry:    pkl = pick_pkl()    if not pkl:        (R/"py_last_trace.txt").write_text("No PKL under intent/**/artifacts\n", encoding="utf-8")        print("[FATAL] æ‰¾ä¸åˆ° intent/**/artifacts/*.pkl"); sys.exit(2)    print("[PKL]", pkl)    est = unwrap(joblib.load(pkl))    pre = dict(est.steps).get("features") if hasattr(est, "steps") else None    clf = est.steps[-1][1] if hasattr(est, "steps") else est    expected = getattr(clf, "n_features_in_", None)    if expected is None and hasattr(clf, "base_estimator"):        expected = getattr(clf.base_estimator, "n_features_in_", None)    expected = int(expected) if expected is not None else None    xs = ["å ±åƒ¹èˆ‡äº¤æœŸ","æŠ€è¡“æ”¯æ´","ç™¼ç¥¨æŠ¬é ­","é€€è¨‚é€£çµ"]    dims = feature_dims(pre, xs) if pre is not None else {}    sum_before = sum(v for v in dims.values() if isinstance(v,int))    print("[PIPELINE_STEPS]", [(n, s.__class__.__name__) for n,s in getattr(est, "steps", [])])    print("[EXPECTED]", expected)    print("[BRANCH_DIMS]", json.dumps(dims, ensure_ascii=False))    print("[SUM_BEFORE]", sum_before)    # pad å°é½Šï¼ˆæ‰¾åå« pad/zero çš„ transformer ä¸¦èª¿æ•´ widthï¼‰    if expected and sum_before and expected != sum_before and hasattr(pre, "transformer_list"):        delta = expected - sum_before        for i, (name, sub) in enumerate(pre.transformer_list):            n = name.lower()            if any(k in n for k in ("pad","zero")) and hasattr(sub, "width"):                old = int(getattr(sub, "width", 1) or 1)                setattr(sub, "width", int(old + delta))                pre.transformer_list[i] = (name, sub)                print("[PAD_ADD]", name, f"+{delta}")                break[7m    out = Path("artifacts")/"intent_pipeline_aligned.pkl"[27m[7m    joblib.dump(est, out)[27m[7m    print("[SAVED]", out)[27m[7m    zh = {"biz_quote":"å ±åƒ¹","tech_support":"æŠ€è¡“æ”¯æ´","complaint":"æŠ•è¨´","policy_qa":"è¦å‰‡è©¢å•","profile_update":"è³‡æ–™ [27m[7mç•°å‹•","other":"å…¶ä»–"}[27m[7m    tests = ["æ‚¨å¥½ï¼Œæƒ³è©¢å•å ±åƒ¹èˆ‡äº¤æœŸ","è«‹å”åŠ©é–‹ç«‹ä¸‰è¯ç™¼ç¥¨æŠ¬é ­","éœ€è¦æŠ€è¡“æ”¯æ´å”åŠ©ï¼Œé™„ä»¶é€£ä¸ä¸Š","é€€è¨‚é€£çµåœ¨æ­¤"][27m[7m    try:[27m[7m        pred = est.predict(tests)[27m[7m        for s,y in zip(tests,pred):[27m[7m            print("   ", s, "->", f"{y} / {zh.get(str(y), str(y))}")[27m[7m        (R/"sample_pred.json").write_text(json.dumps({"samples":tests,"pred":[str(x) for x in pred]}, ensure_ascii=False[27m[7m, indent=2), encoding="utf-8")[27m[7m    except Exception:[27m[7m        (R/"py_last_trace.txt").write_text(traceback.format_exc(), encoding="utf-8")[27m[7m        raise[27m[7m    # è¨ºæ–·æª”[27m[7m    (R/"diagnostics.json").write_text(json.dumps({[27m[7m        "steps": [(n, s.__class__.__name__) for n,s in getattr(est,"steps",[])],[27m[7m        "branch_dims": dims, "expected_dim": expected, "sum_before": sum_before[27m[7m    }, ensure_ascii=False, indent=2), encoding="utf-8")[27m[7mexcept Exception:[27m[7m    (R/"py_last_trace.txt").write_text(traceback.format_exc(), encoding="utf-8")[27m[7m    raise[27m[7mPY[27m[7m# 3) æˆåŠŸæˆ–å¤±æ•—éƒ½é–‹è³‡æ–™å¤¾[27m[7mopen_dir[27m[7mecho "åˆ‡åˆ°é€™é¡†ï¼š export SMA_INTENT_ML_PKL=\"$PWD/artifacts/intent_pipeline_aligned.pkl\""[27m    out = Path("artifacts")/"intent_pipeline_aligned.pkl"    joblib.dump(est, out)    print("[SAVED]", out)    zh = {"biz_quote":"å ±åƒ¹","tech_support":"æŠ€è¡“æ”¯æ´","complaint":"æŠ•è¨´","policy_qa":"è¦å‰‡è©¢å•","profile_update":"è³‡æ–™ ç•°å‹•","other":"å…¶ä»–"}    tests = ["æ‚¨å¥½ï¼Œæƒ³è©¢å•å ±åƒ¹èˆ‡äº¤æœŸ","è«‹å”åŠ©é–‹ç«‹ä¸‰è¯ç™¼ç¥¨æŠ¬é ­","éœ€è¦æŠ€è¡“æ”¯æ´å”åŠ©ï¼Œé™„ä»¶é€£ä¸ä¸Š","é€€è¨‚é€£çµåœ¨æ­¤"]    try:        pred = est.predict(tests)        for s,y in zip(tests,pred):            print("   ", s, "->", f"{y} / {zh.get(str(y), str(y))}")        (R/"sample_pred.json").write_text(json.dumps({"samples":tests,"pred":[str(x) for x in pred]}, ensure_ascii=False, indent=2), encoding="utf-8")    except Exception:        (R/"py_last_trace.txt").write_text(traceback.format_exc(), encoding="utf-8")        raise    # è¨ºæ–·æª”    (R/"diagnostics.json").write_text(json.dumps({        "steps": [(n, s.__class__.__name__) for n,s in getattr(est,"steps",[])],        "branch_dims": dims, "expected_dim": expected, "sum_before": sum_before    }, ensure_ascii=False, indent=2), encoding="utf-8")except Exception:    (R/"py_last_trace.txt").write_text(traceback.format_exc(), encoding="utf-8")    raisePY# 3) æˆåŠŸæˆ–å¤±æ•—éƒ½é–‹è³‡æ–™å¤¾open_direcho "åˆ‡åˆ°é€™é¡†ï¼š export SMA_INTENT_ML_PKL=\"$PWD/artifacts/intent_pipeline_aligned.pkl\""
[?2004l[*] LOGDIR = reports_auto/intent_fix_full/20250915T003438
[PKL] intent/intent/artifacts/intent_pro_cal.pkl
Traceback (most recent call last):
  File "<stdin>", line 51, in <module>
  File "/home/youjie/projects/smart-mail-agent-ssot-pro/.venv/lib/python3.10/site-packages/joblib/numpy_pickle.py", line 749, in load
    obj = _unpickle(
  File "/home/youjie/projects/smart-mail-agent-ssot-pro/.venv/lib/python3.10/site-packages/joblib/numpy_pickle.py", line 626, in _unpickle
    obj = unpickler.load()
  File "/usr/lib/python3.10/pickle.py", line 1213, in load
    dispatch[key[0]](self)
  File "/usr/lib/python3.10/pickle.py", line 1538, in load_stack_global
    self.append(self.find_class(module, name))
  File "/usr/lib/python3.10/pickle.py", line 1582, in find_class
    return _getattribute(sys.modules[module], name)[0]
  File "/usr/lib/python3.10/pickle.py", line 331, in _getattribute
    raise AttributeError("Can't get attribute {!r} on {!r}"
AttributeError: Can't get attribute 'rules_feat' on <module '__main__' (built-in)>
[*] å ±å‘Šè³‡æ–™å¤¾ï¼šreports_auto/intent_fix_full/20250915T003438
